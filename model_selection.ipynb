{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "Selection of LDA model hyperparameters by [topic coherence](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "import pickle\n",
    "\n",
    "from my_files import get_text\n",
    "import my_preprocessing\n",
    "from my_preprocessing import clean_text\n",
    "from my_lda import MyCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16842\n",
      "15092\n"
     ]
    }
   ],
   "source": [
    "# load metadata\n",
    "df = my_preprocessing.load_metadata()\n",
    "print(len(df))\n",
    "# drop documents that aren't research articles (front matter, obituaries, etc.)\n",
    "df = my_preprocessing.drop_non_research(df)\n",
    "print(len(df))\n",
    "# generate list of file paths for corpus\n",
    "filelist = ['data/txt/' + file for file in df.filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create corpus with existing dictionary\n",
    "\n",
    "corpus = MyCorpus(filelist, clean_text, dictionary=Dictionary.load('models/dictionary.dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train model with default settings\n",
    "\n",
    "# model = LdaMulticore(corpus=corpus,\n",
    "#                      id2word=corpus.dictionary.id2token,\n",
    "#                      num_topics=25, \n",
    "#                      random_state=42,\n",
    "#                      chunksize=100,\n",
    "#                      passes=10,\n",
    "#                      per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # save trained model\n",
    "# model_path = 'models/lda_25_default.pkl'\n",
    "\n",
    "# with open(model_path, 'wb') as file:\n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load existing model\n",
    "# model_path = 'models/lda_25_default.pkl'\n",
    "\n",
    "# with open(model_path, 'rb') as file:\n",
    "#     model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train more models with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/lda_25_0.0001_0.0001.pkl already exists\n",
      "models/lda_25_0.0001_0.001.pkl already exists\n",
      "models/lda_25_0.0001_0.01.pkl already exists\n",
      "models/lda_25_0.0001_0.1.pkl already exists\n",
      "models/lda_25_0.0001_1.pkl already exists\n",
      "models/lda_25_0.001_0.0001.pkl already exists\n",
      "models/lda_25_0.001_0.001.pkl already exists\n",
      "models/lda_25_0.001_0.01.pkl already exists\n",
      "models/lda_25_0.001_0.1.pkl already exists\n",
      "models/lda_25_0.001_1.pkl already exists\n",
      "models/lda_25_0.01_0.0001.pkl already exists\n",
      "models/lda_25_0.01_0.001.pkl already exists\n",
      "models/lda_25_0.01_0.01.pkl already exists\n",
      "models/lda_25_0.01_0.1.pkl already exists\n",
      "models/lda_25_0.01_1.pkl already exists\n",
      "models/lda_25_0.1_0.0001.pkl already exists\n",
      "models/lda_25_0.1_0.001.pkl already exists\n",
      "models/lda_25_0.1_0.01.pkl already exists\n",
      "models/lda_25_0.1_0.1.pkl already exists\n",
      "models/lda_25_0.1_1.pkl already exists\n",
      "models/lda_25_1_0.0001.pkl already exists\n",
      "models/lda_25_1_0.001.pkl already exists\n",
      "models/lda_25_1_0.01.pkl already exists\n",
      "models/lda_25_1_0.1.pkl already exists\n",
      "models/lda_25_1_1.pkl already exists\n",
      "models/lda_30_0.0001_0.0001.pkl already exists\n",
      "models/lda_30_0.0001_0.001.pkl already exists\n",
      "models/lda_30_0.0001_0.01.pkl already exists\n",
      "models/lda_30_0.0001_0.1.pkl already exists\n",
      "models/lda_30_0.0001_1.pkl already exists\n",
      "models/lda_30_0.001_0.0001.pkl already exists\n",
      "models/lda_30_0.001_0.001.pkl already exists\n",
      "models/lda_30_0.001_0.01.pkl already exists\n",
      "models/lda_30_0.001_0.1.pkl already exists\n",
      "models/lda_30_0.001_1.pkl already exists\n",
      "models/lda_30_0.01_0.0001.pkl already exists\n",
      "models/lda_30_0.01_0.001.pkl already exists\n",
      "models/lda_30_0.01_0.01.pkl already exists\n",
      "models/lda_30_0.01_0.1.pkl already exists\n",
      "models/lda_30_0.01_1.pkl already exists\n",
      "models/lda_30_0.1_0.0001.pkl already exists\n",
      "models/lda_30_0.1_0.001.pkl already exists\n",
      "models/lda_30_0.1_0.01.pkl already exists\n",
      "models/lda_30_0.1_0.1.pkl already exists\n",
      "models/lda_30_0.1_1.pkl already exists\n",
      "models/lda_30_1_0.0001.pkl already exists\n",
      "models/lda_30_1_0.001.pkl already exists\n",
      "models/lda_30_1_0.01.pkl already exists\n",
      "models/lda_30_1_0.1.pkl already exists\n",
      "models/lda_30_1_1.pkl already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_topics_list = [25, 30]\n",
    "alpha_list = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "eta_list = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "for num_topics in num_topics_list:\n",
    "    for alpha in alpha_list:\n",
    "        for eta in eta_list:\n",
    "            model_path = f\"models/lda_{num_topics}_{alpha}_{eta}.pkl\"\n",
    "            if not os.path.exists(model_path):\n",
    "                model = LdaMulticore(corpus=corpus,\n",
    "                    id2word=corpus.dictionary.id2token,\n",
    "                    num_topics=num_topics,\n",
    "                    alpha=alpha,\n",
    "                    eta=eta,\n",
    "                    random_state=42,\n",
    "                    chunksize=100,\n",
    "                    passes=5,\n",
    "                    per_word_topics=True)\n",
    "                with open(model_path, 'wb') as file:\n",
    "                    pickle.dump(model, file)\n",
    "                print(f\"Model {model_path} complete.\")\n",
    "            else:\n",
    "                print(model_path, \"already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure topic [coherence](http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['models/' + filename for filename in os.listdir('models') if filename.endswith('.pkl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "path = model_list[0]\n",
    "with open(path, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=model, texts=corpus, dictionary=corpus.dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/lib/python3.8/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:202: RuntimeWarning: invalid value encountered in true_divide\n",
      "  numerator = (co_occur_count / num_docs) + EPSILON\n",
      "/home/omlean/anaconda3/lib/python3.8/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:203: RuntimeWarning: invalid value encountered in true_divide\n",
      "  denominator = (w_prime_count / num_docs) * (w_star_count / num_docs)\n",
      "/home/omlean/anaconda3/lib/python3.8/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:198: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_doc_prob = co_occur_count / num_docs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  nan\n"
     ]
    }
   ],
   "source": [
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
